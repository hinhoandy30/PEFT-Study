{
  "best_global_step": null,
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 0.14893141708243354,
  "eval_steps": 500,
  "global_step": 500,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.002978628341648671,
      "grad_norm": 20.656797409057617,
      "learning_rate": 4.98659916617034e-05,
      "loss": 2.7179,
      "step": 10
    },
    {
      "epoch": 0.005957256683297342,
      "grad_norm": 20.63279914855957,
      "learning_rate": 4.97170935080405e-05,
      "loss": 2.7114,
      "step": 20
    },
    {
      "epoch": 0.008935885024946012,
      "grad_norm": 0.5877975225448608,
      "learning_rate": 4.95681953543776e-05,
      "loss": 2.7303,
      "step": 30
    },
    {
      "epoch": 0.011914513366594683,
      "grad_norm": 62.106510162353516,
      "learning_rate": 4.941929720071472e-05,
      "loss": 2.6758,
      "step": 40
    },
    {
      "epoch": 0.014893141708243353,
      "grad_norm": 41.164527893066406,
      "learning_rate": 4.927039904705182e-05,
      "loss": 2.6247,
      "step": 50
    },
    {
      "epoch": 0.017871770049892023,
      "grad_norm": 20.56897735595703,
      "learning_rate": 4.912150089338892e-05,
      "loss": 2.6212,
      "step": 60
    },
    {
      "epoch": 0.020850398391540695,
      "grad_norm": 41.093353271484375,
      "learning_rate": 4.8972602739726034e-05,
      "loss": 2.5337,
      "step": 70
    },
    {
      "epoch": 0.023829026733189367,
      "grad_norm": 48.830238342285156,
      "learning_rate": 4.8823704586063135e-05,
      "loss": 2.5893,
      "step": 80
    },
    {
      "epoch": 0.026807655074838038,
      "grad_norm": 20.522705078125,
      "learning_rate": 4.8674806432400236e-05,
      "loss": 2.4618,
      "step": 90
    },
    {
      "epoch": 0.029786283416486706,
      "grad_norm": 0.4885108768939972,
      "learning_rate": 4.8525908278737344e-05,
      "loss": 2.5781,
      "step": 100
    },
    {
      "epoch": 0.03276491175813538,
      "grad_norm": 0.6228224635124207,
      "learning_rate": 4.837701012507445e-05,
      "loss": 2.5904,
      "step": 110
    },
    {
      "epoch": 0.035743540099784046,
      "grad_norm": 81.91409301757812,
      "learning_rate": 4.822811197141155e-05,
      "loss": 2.4839,
      "step": 120
    },
    {
      "epoch": 0.03872216844143272,
      "grad_norm": 0.5278551578521729,
      "learning_rate": 4.807921381774866e-05,
      "loss": 2.5445,
      "step": 130
    },
    {
      "epoch": 0.04170079678308139,
      "grad_norm": 20.457563400268555,
      "learning_rate": 4.793031566408577e-05,
      "loss": 2.5356,
      "step": 140
    },
    {
      "epoch": 0.04467942512473006,
      "grad_norm": 20.840482711791992,
      "learning_rate": 4.778141751042287e-05,
      "loss": 2.5715,
      "step": 150
    },
    {
      "epoch": 0.04765805346637873,
      "grad_norm": 33.16478729248047,
      "learning_rate": 4.763251935675998e-05,
      "loss": 2.5096,
      "step": 160
    },
    {
      "epoch": 0.050636681808027405,
      "grad_norm": 20.417619705200195,
      "learning_rate": 4.7483621203097086e-05,
      "loss": 2.6185,
      "step": 170
    },
    {
      "epoch": 0.053615310149676076,
      "grad_norm": 20.403322219848633,
      "learning_rate": 4.733472304943419e-05,
      "loss": 2.5628,
      "step": 180
    },
    {
      "epoch": 0.05659393849132475,
      "grad_norm": 0.5793325304985046,
      "learning_rate": 4.7185824895771295e-05,
      "loss": 2.5672,
      "step": 190
    },
    {
      "epoch": 0.05957256683297341,
      "grad_norm": 20.373172760009766,
      "learning_rate": 4.70369267421084e-05,
      "loss": 2.5194,
      "step": 200
    },
    {
      "epoch": 0.06255119517462208,
      "grad_norm": 40.70288848876953,
      "learning_rate": 4.6888028588445504e-05,
      "loss": 2.4161,
      "step": 210
    },
    {
      "epoch": 0.06552982351627076,
      "grad_norm": 0.4232824742794037,
      "learning_rate": 4.673913043478261e-05,
      "loss": 2.5135,
      "step": 220
    },
    {
      "epoch": 0.06850845185791943,
      "grad_norm": 0.6418070793151855,
      "learning_rate": 4.659023228111972e-05,
      "loss": 2.5485,
      "step": 230
    },
    {
      "epoch": 0.07148708019956809,
      "grad_norm": 60.94736862182617,
      "learning_rate": 4.644133412745682e-05,
      "loss": 2.4451,
      "step": 240
    },
    {
      "epoch": 0.07446570854121677,
      "grad_norm": 81.20185089111328,
      "learning_rate": 4.629243597379393e-05,
      "loss": 2.498,
      "step": 250
    },
    {
      "epoch": 0.07744433688286544,
      "grad_norm": 20.294952392578125,
      "learning_rate": 4.6143537820131036e-05,
      "loss": 2.4756,
      "step": 260
    },
    {
      "epoch": 0.08042296522451411,
      "grad_norm": 40.54863739013672,
      "learning_rate": 4.599463966646814e-05,
      "loss": 2.5715,
      "step": 270
    },
    {
      "epoch": 0.08340159356616278,
      "grad_norm": 20.269834518432617,
      "learning_rate": 4.5845741512805245e-05,
      "loss": 2.4481,
      "step": 280
    },
    {
      "epoch": 0.08638022190781146,
      "grad_norm": 20.592130661010742,
      "learning_rate": 4.569684335914235e-05,
      "loss": 2.4991,
      "step": 290
    },
    {
      "epoch": 0.08935885024946012,
      "grad_norm": 0.5783276557922363,
      "learning_rate": 4.5547945205479454e-05,
      "loss": 2.535,
      "step": 300
    },
    {
      "epoch": 0.09233747859110879,
      "grad_norm": 20.237110137939453,
      "learning_rate": 4.539904705181656e-05,
      "loss": 2.4852,
      "step": 310
    },
    {
      "epoch": 0.09531610693275747,
      "grad_norm": 40.43891525268555,
      "learning_rate": 4.525014889815366e-05,
      "loss": 2.4397,
      "step": 320
    },
    {
      "epoch": 0.09829473527440613,
      "grad_norm": 80.8179931640625,
      "learning_rate": 4.510125074449077e-05,
      "loss": 2.3751,
      "step": 330
    },
    {
      "epoch": 0.10127336361605481,
      "grad_norm": 20.19589614868164,
      "learning_rate": 4.495235259082788e-05,
      "loss": 2.3951,
      "step": 340
    },
    {
      "epoch": 0.10425199195770347,
      "grad_norm": 20.18158531188965,
      "learning_rate": 4.480345443716498e-05,
      "loss": 2.4665,
      "step": 350
    },
    {
      "epoch": 0.10723062029935215,
      "grad_norm": 0.4449183940887451,
      "learning_rate": 4.465455628350209e-05,
      "loss": 2.5009,
      "step": 360
    },
    {
      "epoch": 0.11020924864100082,
      "grad_norm": 0.5713348984718323,
      "learning_rate": 4.450565812983919e-05,
      "loss": 2.5774,
      "step": 370
    },
    {
      "epoch": 0.1131878769826495,
      "grad_norm": 20.148977279663086,
      "learning_rate": 4.4356759976176296e-05,
      "loss": 2.5059,
      "step": 380
    },
    {
      "epoch": 0.11616650532429816,
      "grad_norm": 40.26621627807617,
      "learning_rate": 4.4207861822513404e-05,
      "loss": 2.4759,
      "step": 390
    },
    {
      "epoch": 0.11914513366594683,
      "grad_norm": 60.361515045166016,
      "learning_rate": 4.4058963668850505e-05,
      "loss": 2.5303,
      "step": 400
    },
    {
      "epoch": 0.1221237620075955,
      "grad_norm": 0.5397477149963379,
      "learning_rate": 4.391006551518761e-05,
      "loss": 2.3955,
      "step": 410
    },
    {
      "epoch": 0.12510239034924417,
      "grad_norm": 40.20154571533203,
      "learning_rate": 4.376116736152472e-05,
      "loss": 2.5039,
      "step": 420
    },
    {
      "epoch": 0.12808101869089283,
      "grad_norm": 48.5056266784668,
      "learning_rate": 4.361226920786182e-05,
      "loss": 2.4431,
      "step": 430
    },
    {
      "epoch": 0.13105964703254153,
      "grad_norm": 20.083730697631836,
      "learning_rate": 4.346337105419893e-05,
      "loss": 2.4421,
      "step": 440
    },
    {
      "epoch": 0.1340382753741902,
      "grad_norm": 0.5071263909339905,
      "learning_rate": 4.331447290053604e-05,
      "loss": 2.305,
      "step": 450
    },
    {
      "epoch": 0.13701690371583886,
      "grad_norm": 20.05495262145996,
      "learning_rate": 4.316557474687314e-05,
      "loss": 2.4533,
      "step": 460
    },
    {
      "epoch": 0.13999553205748752,
      "grad_norm": 40.075538635253906,
      "learning_rate": 4.3016676593210247e-05,
      "loss": 2.5537,
      "step": 470
    },
    {
      "epoch": 0.14297416039913619,
      "grad_norm": 33.53523635864258,
      "learning_rate": 4.2867778439547354e-05,
      "loss": 2.3681,
      "step": 480
    },
    {
      "epoch": 0.14595278874078488,
      "grad_norm": 40.01968002319336,
      "learning_rate": 4.2718880285884455e-05,
      "loss": 2.5839,
      "step": 490
    },
    {
      "epoch": 0.14893141708243354,
      "grad_norm": 32.37501907348633,
      "learning_rate": 4.256998213222156e-05,
      "loss": 2.4762,
      "step": 500
    }
  ],
  "logging_steps": 10,
  "max_steps": 3358,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 1,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": false
      },
      "attributes": {}
    }
  },
  "total_flos": 2142301338255360.0,
  "train_batch_size": 1,
  "trial_name": null,
  "trial_params": null
}
