{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2d773113",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from peft import LoraConfig,get_peft_model,PeftModel"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00684dfb",
   "metadata": {},
   "source": [
    "# 1. 自定义模型适配"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9640a2e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): Linear(in_features=10, out_features=10, bias=True)\n",
       "  (1): ReLU()\n",
       "  (2): Linear(in_features=10, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net1 = nn.Sequential(\n",
    "    nn.Linear(10,10),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(10,2)\n",
    ")\n",
    "net1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5cbbb1e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.weight\n",
      "0.bias\n",
      "2.weight\n",
      "2.bias\n"
     ]
    }
   ],
   "source": [
    "for name,parm in net1.named_parameters():\n",
    "    print(name)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8979f2e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = LoraConfig(target_modules=[\"0\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "25935133",
   "metadata": {},
   "outputs": [],
   "source": [
    "model1 = get_peft_model(net1,config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9e16bd2c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PeftModel(\n",
       "  (base_model): LoraModel(\n",
       "    (model): Sequential(\n",
       "      (0): lora.Linear(\n",
       "        (base_layer): Linear(in_features=10, out_features=10, bias=True)\n",
       "        (lora_dropout): ModuleDict(\n",
       "          (default): Identity()\n",
       "        )\n",
       "        (lora_A): ModuleDict(\n",
       "          (default): Linear(in_features=10, out_features=8, bias=False)\n",
       "        )\n",
       "        (lora_B): ModuleDict(\n",
       "          (default): Linear(in_features=8, out_features=10, bias=False)\n",
       "        )\n",
       "        (lora_embedding_A): ParameterDict()\n",
       "        (lora_embedding_B): ParameterDict()\n",
       "        (lora_magnitude_vector): ModuleDict()\n",
       "      )\n",
       "      (1): ReLU()\n",
       "      (2): Linear(in_features=10, out_features=2, bias=True)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc40bc3e",
   "metadata": {},
   "source": [
    "# 2. 多适配器加载与切换"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1177a9a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): Linear(in_features=10, out_features=10, bias=True)\n",
       "  (1): ReLU()\n",
       "  (2): Linear(in_features=10, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net2 = nn.Sequential(\n",
    "    nn.Linear(10,10),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(10,2)\n",
    ")\n",
    "net2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "725c39ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "config1 = LoraConfig(target_modules=[\"0\"])\n",
    "model2 = get_peft_model(net2,config1)\n",
    "model2.save_pretrained(\"./loraA\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5babeb9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/liuzhen/Documents/PEFT_Study/.venv/lib/python3.12/site-packages/peft/mapping_func.py:72: UserWarning: You are trying to modify a model with PEFT for a second time. If you want to reload the model with a different config, make sure to call `.unload()` before.\n",
      "  warnings.warn(\n",
      "/Users/liuzhen/Documents/PEFT_Study/.venv/lib/python3.12/site-packages/peft/tuners/tuners_utils.py:282: UserWarning: Already found a `peft_config` attribute in the model. This will lead to having multiple adapters in the model. Make sure to know what you are doing!\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "config2 = LoraConfig(target_modules=[\"2\"])\n",
    "model2 = get_peft_model(net2, config2)\n",
    "model2.save_pretrained(\"./loraB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9923aaa3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PeftModel(\n",
       "  (base_model): LoraModel(\n",
       "    (model): Sequential(\n",
       "      (0): lora.Linear(\n",
       "        (base_layer): Linear(in_features=10, out_features=10, bias=True)\n",
       "        (lora_dropout): ModuleDict(\n",
       "          (default): Identity()\n",
       "          (loraA): Identity()\n",
       "        )\n",
       "        (lora_A): ModuleDict(\n",
       "          (default): Linear(in_features=10, out_features=8, bias=False)\n",
       "          (loraA): Linear(in_features=10, out_features=8, bias=False)\n",
       "        )\n",
       "        (lora_B): ModuleDict(\n",
       "          (default): Linear(in_features=8, out_features=10, bias=False)\n",
       "          (loraA): Linear(in_features=8, out_features=10, bias=False)\n",
       "        )\n",
       "        (lora_embedding_A): ParameterDict()\n",
       "        (lora_embedding_B): ParameterDict()\n",
       "        (lora_magnitude_vector): ModuleDict()\n",
       "      )\n",
       "      (1): ReLU()\n",
       "      (2): lora.Linear(\n",
       "        (base_layer): Linear(in_features=10, out_features=2, bias=True)\n",
       "        (lora_dropout): ModuleDict(\n",
       "          (default): Identity()\n",
       "        )\n",
       "        (lora_A): ModuleDict(\n",
       "          (default): Linear(in_features=10, out_features=8, bias=False)\n",
       "        )\n",
       "        (lora_B): ModuleDict(\n",
       "          (default): Linear(in_features=8, out_features=2, bias=False)\n",
       "        )\n",
       "        (lora_embedding_A): ParameterDict()\n",
       "        (lora_embedding_B): ParameterDict()\n",
       "        (lora_magnitude_vector): ModuleDict()\n",
       "      )\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2 = PeftModel.from_pretrained(net2, model_id=\"./loraA/\", adapter_name=\"loraA\")\n",
    "model2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "131345b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PeftModel(\n",
       "  (base_model): LoraModel(\n",
       "    (model): Sequential(\n",
       "      (0): lora.Linear(\n",
       "        (base_layer): Linear(in_features=10, out_features=10, bias=True)\n",
       "        (lora_dropout): ModuleDict(\n",
       "          (default): Identity()\n",
       "          (loraA): Identity()\n",
       "        )\n",
       "        (lora_A): ModuleDict(\n",
       "          (default): Linear(in_features=10, out_features=8, bias=False)\n",
       "          (loraA): Linear(in_features=10, out_features=8, bias=False)\n",
       "        )\n",
       "        (lora_B): ModuleDict(\n",
       "          (default): Linear(in_features=8, out_features=10, bias=False)\n",
       "          (loraA): Linear(in_features=8, out_features=10, bias=False)\n",
       "        )\n",
       "        (lora_embedding_A): ParameterDict()\n",
       "        (lora_embedding_B): ParameterDict()\n",
       "        (lora_magnitude_vector): ModuleDict()\n",
       "      )\n",
       "      (1): ReLU()\n",
       "      (2): lora.Linear(\n",
       "        (base_layer): Linear(in_features=10, out_features=2, bias=True)\n",
       "        (lora_dropout): ModuleDict(\n",
       "          (default): Identity()\n",
       "          (loraB): Identity()\n",
       "        )\n",
       "        (lora_A): ModuleDict(\n",
       "          (default): Linear(in_features=10, out_features=8, bias=False)\n",
       "          (loraB): Linear(in_features=10, out_features=8, bias=False)\n",
       "        )\n",
       "        (lora_B): ModuleDict(\n",
       "          (default): Linear(in_features=8, out_features=2, bias=False)\n",
       "          (loraB): Linear(in_features=8, out_features=2, bias=False)\n",
       "        )\n",
       "        (lora_embedding_A): ParameterDict()\n",
       "        (lora_embedding_B): ParameterDict()\n",
       "        (lora_magnitude_vector): ModuleDict()\n",
       "      )\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2.load_adapter(\"./loraB/\", adapter_name=\"loraB\")\n",
    "model2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "50505ee9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'loraA'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2.active_adapter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3c26a652",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.4554, -2.5740]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2(torch.arange(0, 10).view(1, 10).float())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f77e7465",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "base_model.model.0.base_layer.weight Parameter containing:\n",
      "tensor([[-0.0621,  0.0434,  0.0322, -0.1129,  0.2890, -0.0049,  0.2818,  0.0177,\n",
      "          0.2881, -0.0446],\n",
      "        [ 0.0597, -0.2148, -0.2554,  0.0022, -0.1270, -0.0511, -0.2159,  0.0690,\n",
      "          0.0423, -0.2214],\n",
      "        [ 0.2724, -0.2535, -0.2873, -0.2022,  0.1348, -0.0765,  0.0122,  0.0028,\n",
      "          0.1878,  0.2557],\n",
      "        [ 0.0083, -0.2733, -0.0428,  0.0069, -0.1523, -0.0485, -0.0322, -0.1476,\n",
      "          0.1904, -0.2775],\n",
      "        [ 0.0892,  0.1389,  0.1269, -0.2619,  0.1822, -0.1095, -0.1189, -0.2207,\n",
      "         -0.0865,  0.1196],\n",
      "        [-0.0677,  0.2571, -0.3158, -0.0199, -0.1225, -0.2901,  0.0451,  0.1588,\n",
      "          0.1946, -0.3010],\n",
      "        [-0.1767,  0.0783,  0.1378,  0.1358, -0.2111,  0.2290,  0.1890,  0.0943,\n",
      "          0.2156,  0.1094],\n",
      "        [ 0.1753,  0.2050, -0.2076,  0.1502,  0.1677,  0.1737, -0.0322,  0.2930,\n",
      "          0.1243,  0.1071],\n",
      "        [ 0.2326, -0.2203,  0.3072,  0.2820, -0.2275, -0.2437, -0.1784, -0.2526,\n",
      "          0.2790, -0.1292],\n",
      "        [ 0.1165,  0.1803, -0.1890, -0.1653,  0.2352,  0.0983, -0.1917,  0.1479,\n",
      "         -0.2025,  0.3026]])\n",
      "base_model.model.0.base_layer.bias Parameter containing:\n",
      "tensor([-0.2164,  0.2715,  0.1303,  0.2044,  0.0862,  0.3056,  0.1429, -0.1061,\n",
      "         0.0367, -0.1419])\n",
      "base_model.model.0.lora_A.default.weight Parameter containing:\n",
      "tensor([[-3.1409e-01,  1.8296e-01,  1.0560e-01,  1.1106e-02, -1.9050e-01,\n",
      "         -1.0679e-02,  2.6258e-01, -2.1156e-01,  1.1334e-01, -2.2077e-01],\n",
      "        [-7.2741e-02,  2.4122e-01, -2.3965e-01,  9.4926e-02, -1.0295e-01,\n",
      "          1.6671e-01, -1.0327e-01,  1.3075e-01, -2.9623e-01,  2.9589e-01],\n",
      "        [-9.1642e-02,  2.5218e-01,  1.7062e-01,  6.7939e-02,  5.4675e-02,\n",
      "         -1.8039e-01, -1.4924e-04, -2.4352e-01, -2.5237e-01,  1.0979e-01],\n",
      "        [-1.5976e-01, -1.5142e-01,  7.7210e-02, -4.4766e-02, -1.5420e-01,\n",
      "          1.8070e-02, -2.5139e-01, -2.0169e-01,  2.5689e-01, -1.5806e-01],\n",
      "        [ 2.5898e-01,  1.6162e-01, -2.4873e-01, -2.1473e-01, -1.7864e-01,\n",
      "         -1.5791e-01, -3.0999e-01,  2.5785e-01,  9.9101e-02, -1.3061e-01],\n",
      "        [-1.6060e-01,  3.1281e-01, -2.7854e-01,  3.9882e-02,  2.7985e-01,\n",
      "         -7.3859e-02,  1.2433e-01, -5.9471e-02,  2.3327e-01,  2.8767e-01],\n",
      "        [-3.0513e-01,  1.0446e-01,  3.6042e-03,  2.9442e-01, -2.3030e-01,\n",
      "          1.5759e-01,  1.6130e-01, -1.2738e-03, -2.6438e-01, -7.3059e-02],\n",
      "        [-6.0400e-02,  1.4293e-01,  2.0798e-01,  9.6971e-02,  1.0525e-01,\n",
      "          2.9727e-01, -1.5654e-01,  1.8872e-01,  2.8646e-03,  1.7598e-02]])\n",
      "base_model.model.0.lora_A.loraA.weight Parameter containing:\n",
      "tensor([[-3.1409e-01,  1.8296e-01,  1.0560e-01,  1.1106e-02, -1.9050e-01,\n",
      "         -1.0679e-02,  2.6258e-01, -2.1156e-01,  1.1334e-01, -2.2077e-01],\n",
      "        [-7.2741e-02,  2.4122e-01, -2.3965e-01,  9.4926e-02, -1.0295e-01,\n",
      "          1.6671e-01, -1.0327e-01,  1.3075e-01, -2.9623e-01,  2.9589e-01],\n",
      "        [-9.1642e-02,  2.5218e-01,  1.7062e-01,  6.7939e-02,  5.4675e-02,\n",
      "         -1.8039e-01, -1.4924e-04, -2.4352e-01, -2.5237e-01,  1.0979e-01],\n",
      "        [-1.5976e-01, -1.5142e-01,  7.7210e-02, -4.4766e-02, -1.5420e-01,\n",
      "          1.8070e-02, -2.5139e-01, -2.0169e-01,  2.5689e-01, -1.5806e-01],\n",
      "        [ 2.5898e-01,  1.6162e-01, -2.4873e-01, -2.1473e-01, -1.7864e-01,\n",
      "         -1.5791e-01, -3.0999e-01,  2.5785e-01,  9.9101e-02, -1.3061e-01],\n",
      "        [-1.6060e-01,  3.1281e-01, -2.7854e-01,  3.9882e-02,  2.7985e-01,\n",
      "         -7.3859e-02,  1.2433e-01, -5.9471e-02,  2.3327e-01,  2.8767e-01],\n",
      "        [-3.0513e-01,  1.0446e-01,  3.6042e-03,  2.9442e-01, -2.3030e-01,\n",
      "          1.5759e-01,  1.6130e-01, -1.2738e-03, -2.6438e-01, -7.3059e-02],\n",
      "        [-6.0400e-02,  1.4293e-01,  2.0798e-01,  9.6971e-02,  1.0525e-01,\n",
      "          2.9727e-01, -1.5654e-01,  1.8872e-01,  2.8646e-03,  1.7598e-02]])\n",
      "base_model.model.0.lora_B.default.weight Parameter containing:\n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0.]])\n",
      "base_model.model.0.lora_B.loraA.weight Parameter containing:\n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0.]])\n",
      "base_model.model.2.base_layer.weight Parameter containing:\n",
      "tensor([[-0.2254,  0.3130, -0.2809,  0.0089,  0.3094,  0.0392,  0.1663,  0.2868,\n",
      "         -0.0517, -0.0971],\n",
      "        [-0.1725,  0.2916, -0.0973, -0.2271,  0.0708,  0.0055, -0.1861, -0.0589,\n",
      "         -0.1702,  0.0433]])\n",
      "base_model.model.2.base_layer.bias Parameter containing:\n",
      "tensor([-0.1504, -0.2303])\n",
      "base_model.model.2.lora_A.default.weight Parameter containing:\n",
      "tensor([[ 0.0808,  0.0093,  0.1412,  0.2314, -0.1063, -0.0902, -0.2239,  0.1674,\n",
      "         -0.1405, -0.3001],\n",
      "        [ 0.0134, -0.1433, -0.0889, -0.0088,  0.2892,  0.2902,  0.2515, -0.0194,\n",
      "         -0.0627, -0.0472],\n",
      "        [ 0.2051,  0.2356, -0.1684,  0.2857,  0.2025, -0.0694,  0.2123,  0.1981,\n",
      "          0.0987, -0.1226],\n",
      "        [ 0.3154,  0.1774, -0.1937,  0.0178, -0.0257, -0.1533,  0.1625, -0.0195,\n",
      "          0.1196, -0.1738],\n",
      "        [-0.3135,  0.2564,  0.1431, -0.0630, -0.2234,  0.1627, -0.2516, -0.1448,\n",
      "          0.3105, -0.1641],\n",
      "        [ 0.1376,  0.2000,  0.1266, -0.1447,  0.2098,  0.0183,  0.0075, -0.2573,\n",
      "          0.1563,  0.1152],\n",
      "        [-0.1462, -0.1340, -0.1385, -0.0395,  0.0209, -0.0852, -0.0494,  0.2257,\n",
      "         -0.1440, -0.2307],\n",
      "        [-0.0309, -0.2017,  0.2727, -0.0105,  0.1285,  0.1668,  0.2245, -0.1635,\n",
      "          0.2746,  0.2133]])\n",
      "base_model.model.2.lora_A.loraB.weight Parameter containing:\n",
      "tensor([[ 0.0808,  0.0093,  0.1412,  0.2314, -0.1063, -0.0902, -0.2239,  0.1674,\n",
      "         -0.1405, -0.3001],\n",
      "        [ 0.0134, -0.1433, -0.0889, -0.0088,  0.2892,  0.2902,  0.2515, -0.0194,\n",
      "         -0.0627, -0.0472],\n",
      "        [ 0.2051,  0.2356, -0.1684,  0.2857,  0.2025, -0.0694,  0.2123,  0.1981,\n",
      "          0.0987, -0.1226],\n",
      "        [ 0.3154,  0.1774, -0.1937,  0.0178, -0.0257, -0.1533,  0.1625, -0.0195,\n",
      "          0.1196, -0.1738],\n",
      "        [-0.3135,  0.2564,  0.1431, -0.0630, -0.2234,  0.1627, -0.2516, -0.1448,\n",
      "          0.3105, -0.1641],\n",
      "        [ 0.1376,  0.2000,  0.1266, -0.1447,  0.2098,  0.0183,  0.0075, -0.2573,\n",
      "          0.1563,  0.1152],\n",
      "        [-0.1462, -0.1340, -0.1385, -0.0395,  0.0209, -0.0852, -0.0494,  0.2257,\n",
      "         -0.1440, -0.2307],\n",
      "        [-0.0309, -0.2017,  0.2727, -0.0105,  0.1285,  0.1668,  0.2245, -0.1635,\n",
      "          0.2746,  0.2133]])\n",
      "base_model.model.2.lora_B.default.weight Parameter containing:\n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0.]])\n",
      "base_model.model.2.lora_B.loraB.weight Parameter containing:\n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0.]])\n"
     ]
    }
   ],
   "source": [
    "for name, param in model2.named_parameters():\n",
    "    print(name, param)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2ed4d999",
   "metadata": {},
   "outputs": [],
   "source": [
    "for name, param in model2.named_parameters():\n",
    "    if name in [\"base_model.model.0.lora_A.loraA.weight\", \"base_model.model.0.lora_B.loraA.weight\"]:\n",
    "        param.data = torch.ones_like(param)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "64644c90",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 167.4115, -182.9486]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2(torch.arange(0, 10).view(1, 10).float())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1614c8f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "model2.set_adapter(\"loraB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5785a6af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'loraB'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2.active_adapter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "917a5dbf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.4554, -2.5740]], grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2(torch.arange(0,10).view(1,10).float())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "351cce90",
   "metadata": {},
   "source": [
    "# 禁用适配器"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b55a64d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "model2.set_adapter(\"loraA\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6b8ac38b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 167.4115, -182.9486]], grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2(torch.arange(0,10).view(1,10).float())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "afd79e57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.4554, -2.5740]])\n"
     ]
    }
   ],
   "source": [
    "with model2.disable_adapter():\n",
    "    print(model2(torch.arange(0,10).view(1,10).float()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "3f9a7922",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "禁用后输出：\n",
      "tensor([[ 0.4554, -2.5740]])\n"
     ]
    }
   ],
   "source": [
    "# 永久禁用：手动关闭所有适配器层\n",
    "model2.base_model.disable_adapter_layers()\n",
    "\n",
    "# 测试：此时应该只有 Base Model 的效果\n",
    "print(\"禁用后输出：\")\n",
    "print(model2(torch.arange(0, 10).view(1, 10).float()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "19862e1a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'default'"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2.active_adapter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "25fe577f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "恢复后输出：\n",
      "tensor([[ 167.4115, -182.9486]], grad_fn=<AddmmBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# 1. 重新开启适配器层\n",
    "model2.base_model.enable_adapter_layers()\n",
    "\n",
    "# 2. 确保指定了你要用的适配器（以防万一）\n",
    "model2.set_adapter(\"loraA\") \n",
    "\n",
    "# 测试：此时恢复 LoRA 效果\n",
    "print(\"恢复后输出：\")\n",
    "print(model2(torch.arange(0, 10).view(1, 10).float()))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PEFT Study (3.12.12)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
